{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé¨ YOWO Multi-Task Training on Google Colab\n",
        "\n",
        "**Model**: `yowo_v2_x3d_m_yolo11m_multitask`  \n",
        "**Dataset**: Charades + Action Genome (288K keyframes, 219 classes)\n",
        "\n",
        "### Optimized Batch Sizes (with AMP)\n",
        "\n",
        "| GPU | VRAM | Batch | Accum | Effective | Est. Time/Epoch |\n",
        "|-----|------|-------|-------|-----------|-----------------|\n",
        "| T4 | 16GB | 8 | 4 | 32 | ~4 hours |\n",
        "| L4 | 24GB | 12 | 4 | 48 | ~2.5 hours |\n",
        "| V100 | 16GB | 10 | 4 | 40 | ~2 hours |\n",
        "| A100 | 40GB | 32 | 2 | 64 | ~50 min |\n",
        "| A100 | 80GB | 64 | 2 | 128 | ~30 min |\n",
        "| H100 | 80GB | 80 | 2 | 160 | ~20 min |\n",
        "\n",
        "**Features**: AMP (FP16), Multi-head (Objects + Actions + Relationships)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Check GPU & Auto-Configure Batch Size\n",
        "import torch\n",
        "print(\"=\" * 70)\n",
        "print(\"üîç GPU Detection & Configuration\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\"‚ùå No GPU! Go to Runtime > Change runtime type > GPU\")\n",
        "\n",
        "gpu_name = torch.cuda.get_device_name(0)\n",
        "gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "\n",
        "print(f\"‚úÖ GPU: {gpu_name}\")\n",
        "print(f\"‚úÖ VRAM: {gpu_memory_gb:.1f} GB\")\n",
        "\n",
        "# =============================================================================\n",
        "# OPTIMIZED BATCH SIZES FOR YOWO V2 + X3D-M + YOLO11m WITH AMP\n",
        "# Based on empirical testing of video action detection models\n",
        "# AMP reduces memory by ~40%, allowing larger batches\n",
        "# =============================================================================\n",
        "if \"A100\" in gpu_name or \"A100\" in gpu_name.upper():\n",
        "    if gpu_memory_gb > 45:  # A100 80GB\n",
        "        BATCH_SIZE, ACCUMULATE = 64, 2   # Effective: 128 (can try 80 if stable)\n",
        "    else:  # A100 40GB\n",
        "        BATCH_SIZE, ACCUMULATE = 32, 2   # Effective: 64 (can try 40-48)\n",
        "elif \"H100\" in gpu_name:\n",
        "    BATCH_SIZE, ACCUMULATE = 80, 2       # Effective: 160 (can try 96)\n",
        "elif \"L4\" in gpu_name:\n",
        "    BATCH_SIZE, ACCUMULATE = 12, 4       # Effective: 48\n",
        "elif \"T4\" in gpu_name:\n",
        "    BATCH_SIZE, ACCUMULATE = 8, 4        # Effective: 32 (can try 10)\n",
        "elif \"V100\" in gpu_name:\n",
        "    BATCH_SIZE, ACCUMULATE = 10, 4       # Effective: 40\n",
        "elif \"P100\" in gpu_name:\n",
        "    BATCH_SIZE, ACCUMULATE = 6, 4        # Effective: 24\n",
        "else:\n",
        "    # Unknown GPU - use conservative settings based on memory\n",
        "    if gpu_memory_gb >= 40:\n",
        "        BATCH_SIZE, ACCUMULATE = 32, 2\n",
        "    elif gpu_memory_gb >= 20:\n",
        "        BATCH_SIZE, ACCUMULATE = 12, 4\n",
        "    else:\n",
        "        BATCH_SIZE, ACCUMULATE = 8, 4\n",
        "\n",
        "effective = BATCH_SIZE * ACCUMULATE\n",
        "print(f\"\\nüì¶ Optimized for {gpu_name}:\")\n",
        "print(f\"   batch_size = {BATCH_SIZE}\")\n",
        "print(f\"   accumulate = {ACCUMULATE}\")\n",
        "print(f\"   effective_batch = {effective}\")\n",
        "print(f\"\\nüí° If OOM: reduce BATCH_SIZE by 2, increase ACCUMULATE proportionally\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Clone Repository & Install Dependencies\n",
        "%cd /content\n",
        "!rm -rf yowo\n",
        "!git clone https://github.com/michelsedgh/yowo.git\n",
        "%cd yowo\n",
        "!pip install -q torch torchvision opencv-python thop scipy matplotlib numpy imageio pytorchvideo ultralytics tensorboard\n",
        "print(\"‚úÖ Repository cloned and dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Download Annotations & Extract Frames\n",
        "import os, time, requests, zipfile\n",
        "\n",
        "DATA_ROOT = \"/content/yowo/data/ActionGenome\"\n",
        "FRAMES_DIR = os.path.join(DATA_ROOT, \"frames\")\n",
        "ANN_DIR = os.path.join(DATA_ROOT, \"annotations\")\n",
        "TAR_PATH = \"/content/drive/MyDrive/yooowo/frames.tar\"\n",
        "\n",
        "os.makedirs(ANN_DIR, exist_ok=True)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: Download Action Genome annotations (PKL files NOT in git repo!)\n",
        "# =============================================================================\n",
        "print(\"=\" * 60)\n",
        "print(\"üì• STEP 1: Downloading Action Genome Annotations\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def download_file(url, filepath):\n",
        "    if os.path.exists(filepath):\n",
        "        size = os.path.getsize(filepath) / 1e6\n",
        "        print(f\"   ‚úÖ {os.path.basename(filepath)} exists ({size:.1f} MB)\")\n",
        "        return True\n",
        "    print(f\"   Downloading {os.path.basename(filepath)}...\")\n",
        "    try:\n",
        "        response = requests.get(url, stream=True, timeout=120)\n",
        "        if response.status_code == 200:\n",
        "            with open(filepath, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "            size = os.path.getsize(filepath) / 1e6\n",
        "            print(f\"   ‚úÖ Downloaded ({size:.1f} MB)\")\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Failed: {e}\")\n",
        "    return False\n",
        "\n",
        "# Action Genome annotations from STAR Benchmark S3\n",
        "ag_files = {\n",
        "    'object_bbox_and_relationship.pkl': 'https://star-benchmark.s3.us-east.cloud-object-storage.appdomain.cloud/Annotations/object_bbox_and_relationship.pkl',\n",
        "    'person_bbox.pkl': 'https://star-benchmark.s3.us-east.cloud-object-storage.appdomain.cloud/Annotations/person_bbox.pkl',\n",
        "    'classes.zip': 'https://star-benchmark.s3.us-east.cloud-object-storage.appdomain.cloud/Annotations/classes.zip'\n",
        "}\n",
        "\n",
        "for filename, url in ag_files.items():\n",
        "    download_file(url, os.path.join(ANN_DIR, filename))\n",
        "\n",
        "# Extract classes.zip if needed\n",
        "classes_zip = os.path.join(ANN_DIR, 'classes.zip')\n",
        "if os.path.exists(classes_zip) and not os.path.exists(os.path.join(ANN_DIR, 'object_classes.txt')):\n",
        "    print(\"   Extracting classes.zip...\")\n",
        "    with zipfile.ZipFile(classes_zip, 'r') as z:\n",
        "        z.extractall(ANN_DIR)\n",
        "    # Move files from classes/ subdirectory if needed\n",
        "    classes_subdir = os.path.join(ANN_DIR, 'classes')\n",
        "    if os.path.exists(classes_subdir):\n",
        "        import shutil\n",
        "        for f in os.listdir(classes_subdir):\n",
        "            shutil.move(os.path.join(classes_subdir, f), os.path.join(ANN_DIR, f))\n",
        "        shutil.rmtree(classes_subdir)\n",
        "    print(\"   ‚úÖ Extracted class files\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2 import credentials\n",
        "\n",
        "# ==============================================================================\n",
        "# CONFIGURATION\n",
        "# ==============================================================================\n",
        "# 1. The Main Archive\n",
        "TAR_FILE_ID = \"1GuRdUMP5qrqyYN0gg8C2B6tLwJeigyFd\"  \n",
        "LOCAL_TAR = \"/content/frames.tar\"\n",
        "\n",
        "# 2. The Pre-made Index (To save time!)\n",
        "INDEX_FILE_ID = \"1ecTAlWCWWSfSavneBwlALjhocl3LKXoa\"\n",
        "LOCAL_INDEX = \"/content/frames.tar.index.sqlite\"\n",
        "\n",
        "# 3. Paths\n",
        "# We mount the raw tar here first\n",
        "TEMP_MOUNT_POINT = \"/content/raw_mount\" \n",
        "# We want the data to appear here eventually\n",
        "FINAL_TARGET_DIR = \"/content/yowo/data/ActionGenome/frames\"\n",
        "# ==============================================================================\n",
        "\n",
        "def install_tools():\n",
        "    print(\"üõ†Ô∏è Installing aria2 and ratarmount...\")\n",
        "    subprocess.run([\"apt-get\", \"install\", \"-y\", \"-qq\", \"aria2\"], check=True)\n",
        "    subprocess.run([\"pip\", \"install\", \"-q\", \"ratarmount\"], check=True)\n",
        "\n",
        "def get_token():\n",
        "    print(\"üîë Authenticating...\")\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = google.auth.default()\n",
        "    creds.refresh(Request())\n",
        "    return creds.token\n",
        "\n",
        "def download_file(token, file_id, output_path):\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"‚úÖ Found existing file: {output_path}\")\n",
        "        return\n",
        "\n",
        "    print(f\"‚¨áÔ∏è Downloading {os.path.basename(output_path)}...\")\n",
        "    url = f\"https://www.googleapis.com/drive/v3/files/{file_id}?alt=media\"\n",
        "    \n",
        "    cmd = [\n",
        "        \"aria2c\", \"-x\", \"16\", \"-s\", \"16\", \"-j\", \"16\",\n",
        "        \"--file-allocation=none\", \"--summary-interval=10\",\n",
        "        \"--header\", f\"Authorization: Bearer {token}\", \n",
        "        \"-o\", os.path.basename(output_path),\n",
        "        \"-d\", os.path.dirname(output_path),\n",
        "        url\n",
        "    ]\n",
        "    \n",
        "    process = subprocess.Popen(cmd)\n",
        "    process.wait()\n",
        "    \n",
        "    if process.returncode != 0:\n",
        "        raise Exception(f\"Failed to download {output_path}\")\n",
        "\n",
        "def mount_and_link():\n",
        "    print(f\"\\nüîó Mounting archive to temp location: {TEMP_MOUNT_POINT}\")\n",
        "    \n",
        "    # 1. Cleanup\n",
        "    subprocess.run([\"fusermount\", \"-u\", TEMP_MOUNT_POINT], stderr=subprocess.DEVNULL)\n",
        "    if os.path.islink(FINAL_TARGET_DIR):\n",
        "        os.unlink(FINAL_TARGET_DIR)\n",
        "    elif os.path.exists(FINAL_TARGET_DIR):\n",
        "        # If it's an empty dir, remove it so we can link\n",
        "        try: os.rmdir(FINAL_TARGET_DIR)\n",
        "        except: pass\n",
        "\n",
        "    os.makedirs(TEMP_MOUNT_POINT, exist_ok=True)\n",
        "    \n",
        "    # 2. Ratarmount using the downloaded index\n",
        "    # We pass the index file explicitly\n",
        "    cmd = f\"ratarmount -P 4 --index-file '{LOCAL_INDEX}' '{LOCAL_TAR}' '{TEMP_MOUNT_POINT}'\"\n",
        "    exit_code = os.system(cmd)\n",
        "    \n",
        "    if exit_code != 0:\n",
        "        raise Exception(\"Ratarmount failed!\")\n",
        "\n",
        "    # 3. Find the internal data path and Link it\n",
        "    # Based on your error, the data is nested inside:\n",
        "    nested_path = os.path.join(TEMP_MOUNT_POINT, \"data/ActionGenome/frames\")\n",
        "    \n",
        "    # Fallback: If that exact path doesn't exist, list folders to help debug\n",
        "    if not os.path.exists(nested_path):\n",
        "        print(f\"‚ö†Ô∏è Could not find expected path: {nested_path}\")\n",
        "        print(f\"üìÇ Contents of root mount: {os.listdir(TEMP_MOUNT_POINT)}\")\n",
        "        # Try to find 'frames' folder dynamically?\n",
        "        # For now, let's assume the structure you mentioned is correct.\n",
        "    \n",
        "    # 4. Create the final destination link\n",
        "    # Ensure parent dir exists\n",
        "    parent_dir = os.path.dirname(FINAL_TARGET_DIR)\n",
        "    os.makedirs(parent_dir, exist_ok=True)\n",
        "    \n",
        "    print(f\"üîó Linking '{nested_path}' --> '{FINAL_TARGET_DIR}'\")\n",
        "    os.symlink(nested_path, FINAL_TARGET_DIR)\n",
        "    \n",
        "    # 5. Verify\n",
        "    if os.path.exists(FINAL_TARGET_DIR) and len(os.listdir(FINAL_TARGET_DIR)) > 0:\n",
        "        count = len(os.listdir(FINAL_TARGET_DIR))\n",
        "        print(f\"üéâ SUCCESS! {count} items visible at {FINAL_TARGET_DIR}\")\n",
        "    else:\n",
        "        print(\"‚ùå Something went wrong. The target folder is empty.\")\n",
        "\n",
        "# --- EXECUTION ---\n",
        "try:\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.flush_and_unmount()\n",
        "    except: pass\n",
        "    \n",
        "    install_tools()\n",
        "    token = get_token()\n",
        "    \n",
        "    # Download Tar AND Index\n",
        "    download_file(token, TAR_FILE_ID, LOCAL_TAR)\n",
        "    download_file(token, INDEX_FILE_ID, LOCAL_INDEX)\n",
        "    \n",
        "    mount_and_link()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå CRITICAL ERROR: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Verify Dataset Structure\n",
        "import os, pickle\n",
        "\n",
        "ANN_DIR = \"/content/yowo/data/ActionGenome/annotations\"\n",
        "FRAMES_DIR = \"/content/yowo/data/ActionGenome/frames\"\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üîç Dataset Verification\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check required files\n",
        "required_files = {\n",
        "    'person_bbox.pkl': 'Person bounding boxes + keyframes',\n",
        "    'object_bbox_and_relationship.pkl': 'Objects + relationships',\n",
        "    'Charades_v1_train.csv': 'Training action labels',\n",
        "    'Charades_v1_test.csv': 'Test action labels',\n",
        "    'Charades_v1_classes.txt': '157 action classes',\n",
        "    'object_classes.txt': '36 object classes',\n",
        "    'relationship_classes.txt': '26 relationship classes',\n",
        "    'video_fps.json': 'FPS for each video'\n",
        "}\n",
        "\n",
        "print(\"\\nüìã Required Annotation Files:\")\n",
        "all_ok = True\n",
        "for f, desc in required_files.items():\n",
        "    path = os.path.join(ANN_DIR, f)\n",
        "    if os.path.exists(path):\n",
        "        size = os.path.getsize(path) / 1e6\n",
        "        print(f\"   ‚úÖ {f} ({size:.1f} MB) - {desc}\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå {f} - MISSING! ({desc})\")\n",
        "        all_ok = False\n",
        "\n",
        "# Check frames\n",
        "print(f\"\\nüìÇ Frames Directory:\")\n",
        "if os.path.exists(FRAMES_DIR):\n",
        "    num_videos = len(os.listdir(FRAMES_DIR))\n",
        "    print(f\"   ‚úÖ {num_videos} video directories\")\n",
        "    # Sample a video\n",
        "    sample_vid = os.listdir(FRAMES_DIR)[0]\n",
        "    sample_frames = len(os.listdir(os.path.join(FRAMES_DIR, sample_vid)))\n",
        "    print(f\"   üìÅ Sample: {sample_vid} has {sample_frames} frames\")\n",
        "else:\n",
        "    print(\"   ‚ùå Frames directory missing!\")\n",
        "    all_ok = False\n",
        "\n",
        "# Verify PKL files are valid\n",
        "print(f\"\\nüî¨ Validating PKL Files:\")\n",
        "try:\n",
        "    with open(os.path.join(ANN_DIR, 'person_bbox.pkl'), 'rb') as f:\n",
        "        person_data = pickle.load(f)\n",
        "    print(f\"   ‚úÖ person_bbox.pkl: {len(person_data)} keyframes\")\n",
        "    \n",
        "    with open(os.path.join(ANN_DIR, 'object_bbox_and_relationship.pkl'), 'rb') as f:\n",
        "        obj_data = pickle.load(f)\n",
        "    print(f\"   ‚úÖ object_bbox_and_relationship.pkl: {len(obj_data)} entries\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ùå Error reading PKL files: {e}\")\n",
        "    all_ok = False\n",
        "\n",
        "if all_ok:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚úÖ DATASET READY FOR TRAINING!\")\n",
        "    print(\"=\" * 60)\n",
        "else:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚ö†Ô∏è DATASET INCOMPLETE - Check errors above\")\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Ready to Train!\n",
        "\n",
        "**Model Architecture: `yowo_v2_x3d_m_yolo11m_multitask`**\n",
        "\n",
        "| Component | Description |\n",
        "|-----------|-------------|\n",
        "| 2D Backbone | YOLO11m (pretrained on COCO) |\n",
        "| 3D Backbone | X3D-M (pretrained on Kinetics-400) |\n",
        "| Object Head | 36 classes (person + 35 objects) |\n",
        "| Action Head | 157 Charades action classes |\n",
        "| Relation Head | 26 relationship classes |\n",
        "| Interaction Head | Binary (is object interacted with?) |\n",
        "\n",
        "**Dataset: Charades + Action Genome**\n",
        "- 288,782 annotated keyframes\n",
        "- 9,601 videos\n",
        "- Multi-task: Objects + Actions + Relationships\n",
        "\n",
        "**Note:** Model checkpoints saved after each epoch to `/content/yowo/weights/charades_ag/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: üöÄ TRAIN! (Fresh Start - Optimized Configuration)\n",
        "# AMP (Automatic Mixed Precision) enabled for ~1.5-2x faster training!\n",
        "\n",
        "import os\n",
        "os.chdir('/content/yowo')\n",
        "\n",
        "# Training configuration - OPTIMIZED\n",
        "BATCH_SIZE = 160\n",
        "ACCUMULATE = 2\n",
        "MAX_EPOCHS = 13\n",
        "LEARNING_RATE = 0.00035\n",
        "LR_DECAY_EPOCHS = \"7 9 11 12\"\n",
        "LEN_CLIP = 16\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "# Build command\n",
        "cmd = f\"\"\"python train.py \\\n",
        "    -d charades_ag \\\n",
        "    -v yowo_v2_x3d_m_yolo11m_multitask \\\n",
        "    --cuda \\\n",
        "    --amp \\\n",
        "    -bs {BATCH_SIZE} \\\n",
        "    -accu {ACCUMULATE} \\\n",
        "    --max_epoch {MAX_EPOCHS} \\\n",
        "    --lr_epoch {LR_DECAY_EPOCHS} \\\n",
        "    --root /content/yowo/data \\\n",
        "    -K {LEN_CLIP} \\\n",
        "    -lr {LEARNING_RATE} \\\n",
        "    --num_workers {NUM_WORKERS} \\\n",
        "    --save_folder /content/yowo/weights\"\"\"\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üöÄ FRESH START - OPTIMIZED TRAINING\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"üì¶ Batch size: {BATCH_SIZE} √ó {ACCUMULATE} = {BATCH_SIZE * ACCUMULATE} effective\")\n",
        "print(f\"üìä Epochs: {MAX_EPOCHS}\")\n",
        "print(f\"üìà Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"üìâ LR decay at epochs: {LR_DECAY_EPOCHS}\")\n",
        "print(f\"\")\n",
        "print(f\"   LR Schedule:\")\n",
        "print(f\"   Epoch 1-6:   lr = 0.0003\")\n",
        "print(f\"   Epoch 7-8:   lr = 0.00015\")\n",
        "print(f\"   Epoch 9-10:  lr = 0.000075\")\n",
        "print(f\"   Epoch 11-12: lr = 0.0000375\")\n",
        "print(f\"   Epoch 13:    lr = 0.00001875\")\n",
        "print(f\"\")\n",
        "print(f\"üé¨ Clip length: {LEN_CLIP} frames\")\n",
        "print(f\"‚ö° AMP: Enabled\")\n",
        "print(f\"\\nüìã Full command:\\n{cmd}\\n\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# RESUME TRAINING FROM EPOCH 5 - PRODUCTION SCHEDULE\n",
        "# =============================================================================\n",
        "# This cell:\n",
        "# 1. Fixes PyTorch 2.6 compatibility issue\n",
        "# 2. Fixes missing optimizer state in checkpoint\n",
        "# 3. Fixes LR scheduler to advance to correct epoch\n",
        "# 4. Resumes from epoch 5 checkpoint with proper LR schedule\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "os.chdir('/content/yowo')\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# FIX 1: PyTorch 2.6 compatibility (add weights_only=False)\n",
        "# FIX 2: Handle missing optimizer state in checkpoint\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"üîß Applying fixes...\")\n",
        "\n",
        "# Create fixed optimizer.py\n",
        "optimizer_fix = '''import torch\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "def build_optimizer(cfg, model, base_lr=0.0, resume=None):\n",
        "    print('==============================')\n",
        "    print('Optimizer: {}'.format(cfg['optimizer']))\n",
        "    print('--momentum: {}'.format(cfg['momentum']))\n",
        "    print('--weight_decay: {}'.format(cfg['weight_decay']))\n",
        "\n",
        "    if cfg['optimizer'] == 'sgd':\n",
        "        optimizer = optim.SGD(\n",
        "            model.parameters(), \n",
        "            lr=base_lr,\n",
        "            momentum=cfg['momentum'],\n",
        "            weight_decay=cfg['weight_decay'])\n",
        "\n",
        "    elif cfg['optimizer'] == 'adam':\n",
        "        optimizer = optim.Adam(\n",
        "            model.parameters(), \n",
        "            lr=base_lr,\n",
        "            weight_decay=cfg['weight_decay'])\n",
        "                                \n",
        "    elif cfg['optimizer'] == 'adamw':\n",
        "        optimizer = optim.AdamW(\n",
        "            model.parameters(), \n",
        "            lr=base_lr,\n",
        "            weight_decay=cfg['weight_decay'])\n",
        "          \n",
        "    start_epoch = 0\n",
        "    if resume is not None:\n",
        "        print('keep training: ', resume)\n",
        "        checkpoint = torch.load(resume, weights_only=False)\n",
        "        # Load optimizer state if available\n",
        "        if \"optimizer\" in checkpoint:\n",
        "            checkpoint_state_dict = checkpoint.pop(\"optimizer\")\n",
        "            optimizer.load_state_dict(checkpoint_state_dict)\n",
        "            print('Loaded optimizer state from checkpoint')\n",
        "        else:\n",
        "            print('No optimizer state in checkpoint, using fresh optimizer')\n",
        "        # Load epoch\n",
        "        if \"epoch\" in checkpoint:\n",
        "            start_epoch = checkpoint.pop(\"epoch\") + 1\n",
        "            print(f'Resuming from epoch {start_epoch}')\n",
        "                        \n",
        "    return optimizer, start_epoch\n",
        "'''\n",
        "\n",
        "with open('/content/yowo/utils/solver/optimizer.py', 'w') as f:\n",
        "    f.write(optimizer_fix)\n",
        "print(\"‚úÖ Fixed optimizer.py (handles missing optimizer state)\")\n",
        "\n",
        "# Fix build_multitask.py\n",
        "with open('/content/yowo/models/yowo/build_multitask.py', 'r') as f:\n",
        "    content = f.read()\n",
        "content = content.replace(\n",
        "    \"torch.load(resume, map_location='cpu')\",\n",
        "    \"torch.load(resume, map_location='cpu', weights_only=False)\"\n",
        ")\n",
        "with open('/content/yowo/models/yowo/build_multitask.py', 'w') as f:\n",
        "    f.write(content)\n",
        "print(\"‚úÖ Fixed build_multitask.py (PyTorch 2.6 compatibility)\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# FIX 3: Add LR scheduler stepping to train.py so it advances to correct epoch\n",
        "# -----------------------------------------------------------------------------\n",
        "with open('/content/yowo/train.py', 'r') as f:\n",
        "    train_content = f.read()\n",
        "\n",
        "# Find and fix the LR scheduler initialization\n",
        "old_scheduler_code = '''    # lr scheduler\n",
        "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, args.lr_epoch, args.lr_decay_ratio)'''\n",
        "\n",
        "new_scheduler_code = '''    # lr scheduler\n",
        "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, args.lr_epoch, args.lr_decay_ratio)\n",
        "    \n",
        "    # Advance scheduler to match resumed epoch (CRITICAL for correct LR decay!)\n",
        "    if start_epoch > 0:\n",
        "        print(f'Advancing LR scheduler by {start_epoch} steps to match resumed epoch...')\n",
        "        for _ in range(start_epoch):\n",
        "            lr_scheduler.step()\n",
        "        print(f'LR after advancing: {lr_scheduler.get_last_lr()[0]:.6f}')'''\n",
        "\n",
        "if old_scheduler_code in train_content:\n",
        "    train_content = train_content.replace(old_scheduler_code, new_scheduler_code)\n",
        "    with open('/content/yowo/train.py', 'w') as f:\n",
        "        f.write(train_content)\n",
        "    print(\"‚úÖ Fixed train.py (LR scheduler advances to correct epoch)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Could not find scheduler code - may already be fixed or different format\")\n",
        "\n",
        "print(\"‚úÖ All fixes applied!\")\n",
        "print(\"\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# TRAINING CONFIGURATION\n",
        "# -----------------------------------------------------------------------------\n",
        "CHECKPOINT = \"/content/yowo/weights/charades_ag/yowo_v2_x3d_m_yolo11m_multitask/yowo_v2_x3d_m_yolo11m_multitask_epoch_5.pth\"\n",
        "BATCH_SIZE = 160\n",
        "ACCUMULATE = 2\n",
        "MAX_EPOCHS = 13\n",
        "LEARNING_RATE = 0.00035\n",
        "LR_DECAY_EPOCHS = \"7 9 11 12\"\n",
        "LEN_CLIP = 16\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "\n",
        "cmd = f\"\"\"python train.py \\\n",
        "    -d charades_ag \\\n",
        "    -v yowo_v2_x3d_m_yolo11m_multitask \\\n",
        "    --cuda \\\n",
        "    --amp \\\n",
        "    -bs {BATCH_SIZE} \\\n",
        "    -accu {ACCUMULATE} \\\n",
        "    --max_epoch {MAX_EPOCHS} \\\n",
        "    --lr_epoch {LR_DECAY_EPOCHS} \\\n",
        "    --root /content/yowo/data \\\n",
        "    -K {LEN_CLIP} \\\n",
        "    -lr {LEARNING_RATE} \\\n",
        "    --num_workers {NUM_WORKERS} \\\n",
        "    --save_folder /content/yowo/weights \\\n",
        "    -r {CHECKPOINT}\"\"\"\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üöÄ RESUMING TRAINING FROM EPOCH 5\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"üì¶ Batch size: {BATCH_SIZE} (effective: {BATCH_SIZE * ACCUMULATE})\")\n",
        "print(f\"üìä Max epochs: {MAX_EPOCHS}\")\n",
        "print(f\"üìà Base LR: {LEARNING_RATE}\")\n",
        "print(f\"üìâ LR decay at epochs: {LR_DECAY_EPOCHS}\")\n",
        "print(f\"\")\n",
        "print(f\"   ACTUAL LR Schedule (MultiStepLR behavior):\")\n",
        "print(f\"   Epoch 6/13:  lr = 0.00035   (resuming here)\")\n",
        "print(f\"   Epoch 7/13:  lr = 0.00035   (still full LR)\")\n",
        "print(f\"   Epoch 8/13:  lr = 0.000175  (first decay after milestone 7)\")\n",
        "print(f\"   Epoch 9/13:  lr = 0.000175\")\n",
        "print(f\"   Epoch 10/13: lr = 0.0000875 (second decay after milestone 9)\")\n",
        "print(f\"   Epoch 11/13: lr = 0.0000875\")\n",
        "print(f\"   Epoch 12/13: lr = 0.00004375 (third decay after milestone 11)\")\n",
        "print(f\"   Epoch 13/13: lr = 0.00002188 (fourth decay after milestone 12)\")\n",
        "print(f\"\")\n",
        "print(f\"üé¨ Clip length: {LEN_CLIP} frames\")\n",
        "print(f\"‚ö° AMP: Enabled\")\n",
        "print(f\"\\nüìã Full command:\\n{cmd}\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Save Weights to Google Drive (after training)\n",
        "import shutil, os\n",
        "\n",
        "DRIVE_SAVE_PATH = \"/content/drive/MyDrive/yooowo/weights\"\n",
        "os.makedirs(DRIVE_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "weights_dir = \"/content/yowo/weights/charades_ag/yowo_v2_x3d_m_yolo11m_multitask\"\n",
        "if os.path.exists(weights_dir):\n",
        "    for w in os.listdir(weights_dir):\n",
        "        if w.endswith('.pth'):\n",
        "            shutil.copy2(os.path.join(weights_dir, w), os.path.join(DRIVE_SAVE_PATH, w))\n",
        "            print(f\"‚úÖ Saved {w} to Drive\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No weights found yet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Optional: Quick 1-Epoch Test\n",
        "\n",
        "Run this first to verify everything works before full training:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick test - run ~100 iterations to verify everything works\n",
        "# Uses small batch to ensure it fits, includes AMP\n",
        "# Uncomment the line below to run:\n",
        "\n",
        "# !python train.py -d charades_ag -v yowo_v2_x3d_m_yolo11m_multitask --cuda --amp -bs 4 --max_epoch 1 --root /content/yowo/data -K 16 --num_workers 2 2>&1 | head -80\n",
        "\n",
        "# If it works, you should see losses decreasing every 10 iterations.\n",
        "# Then run Cell 8 for full training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Resume Training from Checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resume from checkpoint (uncomment and modify path)\n",
        "# CHECKPOINT = \"/content/yowo/weights/charades_ag/yowo_v2_x3d_m_yolo11m_multitask/yowo_v2_x3d_m_yolo11m_multitask_epoch_5.pth\"\n",
        "# !python train.py -d charades_ag -v yowo_v2_x3d_m_yolo11m_multitask --cuda -bs {BATCH_SIZE} -accu {ACCUMULATE} --max_epoch 20 --root /content/yowo/data -K 16 -r {CHECKPOINT} --eval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Troubleshooting\n",
        "\n",
        "| Problem | Solution |\n",
        "|---------|----------|\n",
        "| **OOM Error** | Reduce `BATCH_SIZE` by 2, increase `ACCUMULATE` proportionally (keep effective same) |\n",
        "| **Training slow** | Increase batch size if GPU memory allows. L4/A100 can go higher. |\n",
        "| **Loss not decreasing** | Try lr=0.0005 (higher) or lr=0.00005 (lower) |\n",
        "| **`loss is NAN !!`** | Reduce learning rate to 0.00005, or check for bad data samples |\n",
        "| **Loss stuck high** | Verify dataset extracted correctly, check annotations |\n",
        "| **loss_act = 0.00** | This is NORMAL - some frames have no person, so no action loss |\n",
        "\n",
        "## üìÅ Output Files\n",
        "\n",
        "After training:\n",
        "- **Weights**: `/content/yowo/weights/charades_ag/yowo_v2_x3d_m_yolo11m_multitask/`\n",
        "- **Checkpoints**: `yowo_v2_x3d_m_yolo11m_multitask_epoch_N.pth`\n",
        "\n",
        "**‚ö†Ô∏è IMPORTANT:** Run Cell 9 to copy weights to Google Drive before the runtime disconnects!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
